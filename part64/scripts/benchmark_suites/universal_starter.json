{
  "id": "universal-model-bench-starter",
  "description": "Starter suite mixing ASR and embedding benchmarks with weighted multi-criteria ranking.",
  "dataset": {
    "source": "hf",
    "id": "hf-internal-testing/librispeech_asr_dummy",
    "config": "clean",
    "split": "validation",
    "max_samples": 24,
    "input_column": "audio",
    "reference_column": "text",
    "sampling_rate": 16000
  },
  "criteria": [
    {
      "id": "asr_quality",
      "metric": "wer",
      "goal": "min",
      "weight": 0.35,
      "runners": ["whisper_asr"]
    },
    {
      "id": "asr_speed",
      "expression": "x_realtime",
      "goal": "max",
      "weight": 0.25,
      "runners": ["whisper_asr"]
    },
    {
      "id": "embed_latency",
      "metric": "p95_latency_ms",
      "goal": "min",
      "weight": 0.2,
      "runners": ["embedding_text"]
    },
    {
      "id": "embed_throughput",
      "metric": "throughput_items_per_second",
      "goal": "max",
      "weight": 0.2,
      "runners": ["embedding_text"]
    }
  ],
  "benchmarks": [
    {
      "id": "whisper_tiny_cpu",
      "runner": "whisper_asr",
      "model": "openai/whisper-tiny.en",
      "device": "CPU",
      "params": {
        "language": "en"
      }
    },
    {
      "id": "whisper_base_npu",
      "runner": "whisper_asr",
      "model": "openai/whisper-base.en",
      "device": "NPU",
      "params": {
        "language": "en"
      }
    },
    {
      "id": "embed_nomic_npu",
      "runner": "embedding_text",
      "model": "nomic-embed-text",
      "device": "NPU",
      "dataset": {
        "source": "hf",
        "id": "hf-internal-testing/librispeech_asr_dummy",
        "config": "clean",
        "split": "validation",
        "max_samples": 64,
        "input_column": "text",
        "reference_column": "text"
      },
      "params": {
        "backend": "openvino",
        "target_dim": 128,
        "max_chars": 1200
      }
    },
    {
      "id": "embed_nomic_cpu",
      "runner": "embedding_text",
      "model": "nomic-embed-text",
      "device": "CPU",
      "dataset": {
        "source": "hf",
        "id": "hf-internal-testing/librispeech_asr_dummy",
        "config": "clean",
        "split": "validation",
        "max_samples": 64,
        "input_column": "text",
        "reference_column": "text"
      },
      "params": {
        "backend": "openvino",
        "target_dim": 128,
        "max_chars": 1200
      }
    }
  ]
}
